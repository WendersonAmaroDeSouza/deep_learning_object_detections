{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "Collecting torch==1.11.0\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\wende\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wende\\anaconda3\\lib\\site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\wende\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wende\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wende\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wende\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\wende\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wende\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.11.0 torchvision-0.12.0\n",
      "Requirement already satisfied: torch in c:\\users\\wende\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wende\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3828/1881981955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image,ImageDraw,ImageOps,ExifTags\n",
    "from IPython.display import display\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Unable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "os.chdir('../datasets/datasets/')\n",
    "from mapeval import voc_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(img):\n",
    "  image_exif = img._getexif()\n",
    "  image_orientation = image_exif[274]\n",
    "  if image_orientation == 3:\n",
    "    rotated = img.rotate(180)\n",
    "  if image_orientation == 6:\n",
    "    rotated = img.rotate(-90)\n",
    "  if image_orientation == 8:\n",
    "    rotated = img.rotate(90)\n",
    "  return rotated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3828/1592035452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'carros/2247813774_e722d94c4b_n.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#img = rotateImage(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "img = Image.open('carros/2247813774_e722d94c4b_n.jpg')\n",
    "#img = rotateImage(img)\n",
    "img = ImageOps.exif_transpose(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.resize((600, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados rotulados de https://www.makesense.ai/\n",
    "h_files = {}\n",
    "with open('/content/drive/MyDrive/class_ia/labels.csv') as csv_file:\n",
    "    for line in csv_file:\n",
    "        v = line.split(',')\n",
    "        class_att = v[0]\n",
    "        x1,y1,x2,y2 = [int(x) for x in v[1:5]]\n",
    "        img_file = v[5]\n",
    "        if img_file not in h_files.keys():\n",
    "            h_files[img_file] = {'boxes':[],'labels':[]}\n",
    "        h_files[img_file]['boxes'].append((x1,y1,x2,y2)) \n",
    "        h_files[img_file]['labels'].append(class_att)\n",
    "\n",
    "for img_file in h_files.keys():\n",
    "    print(img_file)\n",
    "    print(h_files[img_file]['boxes'])\n",
    "    print(h_files[img_file]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    "    def __init__(self,transforms = None):\n",
    "        self.data = []\n",
    "        self.transforms = transforms\n",
    "        self.target_names = ['blanck']\n",
    "        self.htarget_names = {'blanck':0,'vaso flor 1':1,'vaso flor 2':2}\n",
    "        self.read_csv()\n",
    "\n",
    "    def get_label_id(self,name):\n",
    "        if name not in self.htarget_names:\n",
    "            self.htarget_names[name] = len(self.target_names)\n",
    "            self.target_names.append(name)\n",
    "        return self.htarget_names[name]\n",
    "    \n",
    "    def read_csv(self):\n",
    "        h_files = {}\n",
    "        with open('labels.csv') as csv_file:\n",
    "            for line in csv_file:\n",
    "                v = line.split(',')\n",
    "                class_att = v[0]\n",
    "                x1,y1,width,height = [int(x) for x in v[1:5]]\n",
    "                x2 = x1 + width\n",
    "                y2 = y1 + height\n",
    "                img_file = v[5]\n",
    "                if img_file not in h_files.keys():\n",
    "                    h_files[img_file] = {'boxes':[],'labels':[]}\n",
    "                h_files[img_file]['boxes'].append((x1,y1,x2,y2)) \n",
    "                h_files[img_file]['labels'].append(self.get_label_id(class_att))\n",
    "\n",
    "        for img_file in h_files.keys():\n",
    "            h = {}\n",
    "            h['file_img'] = 'imagens/'+img_file\n",
    "            h['labels'] = h_files[img_file]['labels']\n",
    "            h['boxes']  = h_files[img_file]['boxes']\n",
    "            self.data.append(h)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        img   = Image.open(self.data[i]['file_img'])\n",
    "        img   = ImageOps.exif_transpose(img)\n",
    "        img   = img.convert(\"RGB\")\n",
    "        boxes = torch.tensor(self.data[i]['boxes'])\n",
    "        if self.transforms != None:\n",
    "            img,boxes = self.transforms(img,boxes)\n",
    "        r = dict()\n",
    "        r['boxes']   = boxes\n",
    "        r['labels']  = torch.tensor(self.data[i]['labels'])\n",
    "        return img,r\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img,boxes,size):\n",
    "    w, h = img.size\n",
    "    ow, oh = size\n",
    "    sw = float(ow) / w\n",
    "    sh = float(oh) / h\n",
    "    img = img.resize((ow,oh), Image.BILINEAR)\n",
    "    boxes = boxes * torch.tensor([sw,sh,sw,sh])\n",
    "    return img, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (300,300)\n",
    "def transform_data(img,boxes):\n",
    "    img,boxes = resize(img,boxes,size)\n",
    "    img = T.Compose([\n",
    "          T.ToTensor(),\n",
    "          #(image - mean) / std\n",
    "          T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))          \n",
    "    ])(img)\n",
    "    return img,boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MyDataset(transforms=transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "n_treino = int(0.7*n)\n",
    "n_teste  = n-n_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,n_treino,n_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_treino,ds_teste = torch.utils.data.random_split(data,(n_treino,n_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "dl_treino = torch.utils.data.DataLoader(ds_treino,batch_size = 8,collate_fn=collate_fn)\n",
    "dl_teste  = torch.utils.data.DataLoader(ds_teste,batch_size = 12,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,targets = next(iter(dl_treino))\n",
    "imgs_teste,targets_teste = next(iter(dl_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nview = ImageOps.exif_transpose(Image.open(data.data[0]['file_img']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[0]['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img,boxes,labels):\n",
    "    imdraw = ImageDraw.Draw(img)\n",
    "    for (box,label) in zip(boxes,labels):\n",
    "        box = list(box)\n",
    "        imdraw.rectangle(box,outline='red')\n",
    "        text = \"%d\"%(label)\n",
    "        imdraw.text((box[0],box[1]),text,fill='red')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(nview,data.data[0]['boxes'],data.data[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nview = T.ToPILImage()(imgs[0]*torch.Tensor([0.229,0.224,0.225]).view(3,1,1)+torch.Tensor([0.485,0.456,0.406]).view(3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(nview,targets[0]['boxes'],targets[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tunning\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    bloss=[]\n",
    "    for images,targets in dl_treino:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k:v.to(device) for k,v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images,targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        losses.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        for loss in loss_dict.keys():\n",
    "            print(\"%.10s %4.3f\"%(loss,loss_dict[loss].item()))\n",
    "        print(\"Total Loss %4.3f\\n\"%(losses))\n",
    "        bloss.append(losses.item())\n",
    "    \n",
    "    print(\"\\nEPOCH %d LR %5.5f\\n\"%(epoch,opt.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    pred_boxes = []\n",
    "    pred_labels = []\n",
    "    pred_scores = []\n",
    "    gt_boxes = []\n",
    "    gt_labels = []\n",
    "    lmap = []\n",
    "    lap  = []\n",
    "    with torch.no_grad():\n",
    "        for images,targets in dl_teste:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            pred   = model(images)\n",
    "            for i in range(len(targets)):\n",
    "                gt_boxes.append(targets[i]['boxes'])\n",
    "                gt_labels.append(targets[i]['labels'])\n",
    "                pred_boxes.append(pred[i]['boxes'].cpu())\n",
    "                pred_labels.append(pred[i]['labels'].cpu())\n",
    "                pred_scores.append(pred[i]['scores'].cpu())\n",
    "                r = voc_eval(pred_boxes, pred_labels, pred_scores,\n",
    "                gt_boxes, gt_labels)\n",
    "                lmap.append(r['map'])\n",
    "    #print(np.mean(lmap))\n",
    "    print(\"mAP %.2f\\n\"%(np.mean(lmap)))\n",
    "    return np.mean(lmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_map = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    map = evaluate(epoch)\n",
    "    lr_scheduler.step(1.0-map)\n",
    "    if map > best_map:\n",
    "        best_map = map\n",
    "        torch.save(model,'best_map_labelbox.pth')\n",
    "        print('saving model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('best_map_labelbox.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pos = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nview = T.ToPILImage()(imgs[image_pos]*torch.Tensor([0.229,0.224,0.225]).view(3,1,1)+torch.Tensor([0.485,0.456,0.406]).view(3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred   = model(imgs[image_pos].view([1,3,300,300]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]['boxes'][:2],pred[0]['labels'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(nview,pred[0]['boxes'][:2],pred[0]['labels'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62ec49213e192229414383642b87123a9687b67963751bf1270415605849f672"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
